{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca41bf36-186d-4829-a5d9-d21b98e7391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of rows in the maze:  5\n",
      "Enter number of columns in the maze:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the maze layout row by row (0 = free path, 1 = wall):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Row 1:  0 0 1 0 0\n",
      "Row 2:  0 0 1 0 0\n",
      "Row 3:  0 0 0 0 0\n",
      "Row 4:  0 1 1 1 0\n",
      "Row 5:  0 0 0 0 0\n",
      "Enter start position (row col):  0 0\n",
      "Enter goal position (row col):  4 4\n",
      "Enter learning rate alpha (e.g., 0.1):  0.1\n",
      "Enter discount factor gamma (e.g., 0.9):  0.9\n",
      "Enter exploration rate epsilon (e.g., 0.2):   0.1\n",
      "Enter number of episodes for training:   10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "\n",
      "Optimal path found by the agent:\n",
      "[(0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4)]\n",
      "\n",
      "Maze with Optimal Path:\n",
      "S . █ . .\n",
      "* * █ . .\n",
      ". * * * *\n",
      ". █ █ █ *\n",
      ". . . . G\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- 1. GET MAZE AND PARAMETERS FROM USER ---\n",
    "rows = int(input(\"Enter number of rows in the maze: \"))\n",
    "cols = int(input(\"Enter number of columns in the maze: \"))\n",
    "\n",
    "print(\"Enter the maze layout row by row (0 = free path, 1 = wall):\")\n",
    "maze = []\n",
    "for r in range(rows):\n",
    "    while True:\n",
    "        row = input(f\"Row {r + 1}: \").strip().split()\n",
    "        if len(row) == cols and all(cell in ['0', '1'] for cell in row):\n",
    "            maze.append([int(cell) for cell in row])\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Invalid input. Please enter exactly {cols} numbers (0 or 1), separated by spaces.\")\n",
    "maze = np.array(maze)\n",
    "\n",
    "def get_position(prompt):\n",
    "    \"\"\"Safely gets a valid (row, col) position from the user.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            pos = tuple(map(int, input(prompt).split()))\n",
    "            if 0 <= pos[0] < rows and 0 <= pos[1] < cols and maze[pos[0], pos[1]] == 0:\n",
    "                return pos\n",
    "            else:\n",
    "                print(\"Position is outside the maze, invalid, or is a wall. Try again.\")\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"Invalid format. Please enter two integers separated by a space (e.g., '0 1').\")\n",
    "\n",
    "start = get_position(\"Enter start position (row col): \")\n",
    "goal = get_position(\"Enter goal position (row col): \")\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "alpha = float(input(\"Enter learning rate alpha (e.g., 0.1): \"))\n",
    "gamma = float(input(\"Enter discount factor gamma (e.g., 0.9): \"))\n",
    "epsilon = float(input(\"Enter exploration rate epsilon (e.g., 0.2): \"))\n",
    "episodes = int(input(\"Enter number of episodes for training: \"))\n",
    "\n",
    "# --- 2. DEFINE THE Q-LEARNING ENVIRONMENT ---\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "state_size = rows * cols\n",
    "action_size = len(actions)\n",
    "\n",
    "def state_index(pos):\n",
    "    \"\"\"Converts a (row, col) tuple to a single state index.\"\"\"\n",
    "    return pos[0] * cols + pos[1]\n",
    "\n",
    "def is_valid(pos):\n",
    "    \"\"\"Checks if a position is within bounds and not a wall.\"\"\"\n",
    "    r, c = pos\n",
    "    return 0 <= r < rows and 0 <= c < cols and maze[r, c] == 0\n",
    "\n",
    "def step(pos, action):\n",
    "    \"\"\"Performs an action, returns the new position and reward.\"\"\"\n",
    "    r, c = pos\n",
    "    if action == 'up': r -= 1\n",
    "    elif action == 'down': r += 1\n",
    "    elif action == 'left': c -= 1\n",
    "    elif action == 'right': c += 1\n",
    "    \n",
    "    new_pos = (r, c)\n",
    "    # If the move is invalid (hits a wall or goes off-grid), stay put\n",
    "    if not is_valid(new_pos):\n",
    "        new_pos = pos\n",
    "        reward = -5 # Heavier penalty for hitting a wall\n",
    "    elif new_pos == goal:\n",
    "        reward = 100 # Large reward for reaching the goal\n",
    "    else:\n",
    "        reward = -1 # Small cost for each step to encourage shorter paths\n",
    "        \n",
    "    return new_pos, reward\n",
    "\n",
    "# --- 3. TRAIN THE AGENT ---\n",
    "Q = np.zeros((state_size, action_size))\n",
    "\n",
    "for ep in range(episodes):\n",
    "    pos = start\n",
    "    while pos != goal:\n",
    "        state = state_index(pos)\n",
    "        \n",
    "        # Epsilon-greedy strategy for action selection\n",
    "        if random.random() < epsilon:\n",
    "            action_idx = random.randint(0, action_size - 1) # Explore\n",
    "        else:\n",
    "            action_idx = np.argmax(Q[state]) # Exploit\n",
    "        \n",
    "        action = actions[action_idx]\n",
    "        new_pos, reward = step(pos, action)\n",
    "        new_state = state_index(new_pos)\n",
    "        \n",
    "        # The Q-learning update formula\n",
    "        # Q(s,a) = Q(s,a) + alpha * [R + gamma * max_a'(Q(s',a')) - Q(s,a)]\n",
    "        Q[state, action_idx] += alpha * (reward + gamma * np.max(Q[new_state]) - Q[state, action_idx])\n",
    "        \n",
    "        pos = new_pos\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# --- 4. EXTRACT AND DISPLAY THE OPTIMAL PATH ---\n",
    "def print_maze_with_path(maze, path, start, goal):\n",
    "    \"\"\"Visualizes the maze with the found path.\"\"\"\n",
    "    # Create a copy for visualization, using strings for symbols\n",
    "    vis_maze = np.full(maze.shape, '.', dtype=str)\n",
    "    vis_maze[maze == 1] = '█' # Use a block character for walls\n",
    "\n",
    "    # Mark the path, making sure not to overwrite start/goal\n",
    "    for r, c in path:\n",
    "        if (r, c) != start and (r, c) != goal:\n",
    "            vis_maze[r, c] = '*'\n",
    "            \n",
    "    vis_maze[start] = 'S' # Mark start\n",
    "    vis_maze[goal] = 'G'  # Mark goal\n",
    "\n",
    "    print(\"\\nMaze with Optimal Path:\")\n",
    "    for row in vis_maze:\n",
    "        print(' '.join(row))\n",
    "\n",
    "pos = start\n",
    "path = [pos]\n",
    "step_count = 0\n",
    "max_steps = rows * cols # Safety break to prevent infinite loops\n",
    "\n",
    "while pos != goal and step_count < max_steps:\n",
    "    state = state_index(pos)\n",
    "    action_idx = np.argmax(Q[state])\n",
    "    action = actions[action_idx]\n",
    "    pos, _ = step(pos, action)\n",
    "    \n",
    "    # Avoid adding the same position twice if stuck\n",
    "    if pos not in path:\n",
    "      path.append(pos)\n",
    "    step_count += 1\n",
    "\n",
    "# --- Display Results ---\n",
    "if pos == goal:\n",
    "    print(\"\\nOptimal path found by the agent:\")\n",
    "    print(path)\n",
    "    print_maze_with_path(maze, path, start, goal)\n",
    "else:\n",
    "    print(\"\\nCould not find a path to the goal after training.\")\n",
    "    print(\"Consider increasing episodes or adjusting hyperparameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be759be4-fe6a-4d5c-9143-7a7e9f7d6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
